# Travel Planner V2 - Deployment Guide

Complete guide for deploying and using Travel Planner V2 with FastAPI, Streamlit, and LangSmith monitoring.

## üöÄ Quick Start

### 1. Installation

```bash
# Clone repository
git clone <your-repo-url>
cd travel-planner-deepagent

# Install dependencies with UV (recommended)
uv sync

# Or with pip
pip install -e .
```

### 2. Environment Setup

```bash
# Copy environment template
cp .env.example .env

# Edit .env with your API keys
nano .env  # or your preferred editor
```

**Required variables:**
```bash
# At least one LLM provider
ANTHROPIC_API_KEY=sk-ant-...
# OR
OPENAI_API_KEY=sk-...
# OR
OPENROUTER_API_KEY=sk-or-...

# Provider configuration
LLM_PROVIDER=anthropic  # or openai, openrouter
LLM_MODEL=              # optional, uses default if empty
```

**Optional but recommended for V2:**
```bash
# LangSmith monitoring
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=ls__...
LANGCHAIN_PROJECT=travel-planner-v2
```

---

## üåê Deployment Options

### Option 1: FastAPI REST API

**Start the API server:**

```bash
# Development mode (auto-reload)
uvicorn api_v2:app --reload --port 8000

# Production mode
uvicorn api_v2:app --host 0.0.0.0 --port 8000 --workers 4
```

**Access:**
- API: http://localhost:8000
- Swagger Docs: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

**Example API calls:**

```bash
# Health check
curl http://localhost:8000/health

# Plan a trip
curl -X POST http://localhost:8000/api/v2/plan-trip \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Plan a 5-day trip to Tokyo in March",
    "origin": "New York",
    "num_passengers": 2,
    "budget": 5000,
    "preferences": {
      "cabin_class": "economy",
      "hotel_rating": 4,
      "activities": ["museums", "restaurants"]
    }
  }'

# Search flights only
curl -X POST http://localhost:8000/api/v2/search-flights \
  -H "Content-Type: application/json" \
  -d '{
    "origin": "Istanbul",
    "destination": "Paris",
    "departure_date": "2024-12-20",
    "return_date": "2024-12-27",
    "num_passengers": 2
  }'
```

**Python client example:**

```python
import requests

url = "http://localhost:8000/api/v2/plan-trip"
data = {
    "query": "Plan a weekend trip to Barcelona",
    "num_passengers": 2,
    "budget": 2000
}

response = requests.post(url, json=data)
result = response.json()

print(result["itinerary"])
print(f"Total cost: ${result['total_cost']}")
```

---

### Option 2: Streamlit Chat Interface

**Start the Streamlit app:**

```bash
streamlit run streamlit_chat_v2.py
```

**Access:** http://localhost:8501

**Features:**
- ‚úÖ **Context Preservation**: Remembers your conversation
- ‚úÖ **Interactive Chat**: Natural conversation flow
- ‚úÖ **Real-time Updates**: See results as they come
- ‚úÖ **Session Management**: Multiple conversations
- ‚úÖ **Visual Feedback**: Metrics and progress indicators

**Usage:**
1. Configure settings in the sidebar (provider, model, monitoring)
2. Click "Initialize Planner"
3. Start chatting!

**Example conversation:**
```
You: I want to plan a trip to Paris
Assistant: [Asks for details]

You: Flying from Istanbul, December 20-27, 2 people
Assistant: [Provides flight and hotel options]

You: Show me activities for families
Assistant: [Lists family-friendly activities, remembers your trip context]
```

---

### Option 3: Python Library (Programmatic)

**Direct usage in Python:**

```python
import asyncio
from src_v2 import TravelPlannerV2

async def main():
    # Initialize planner
    planner = TravelPlannerV2(
        provider="anthropic",
        verbose=True,
        enable_monitoring=True
    )

    # Plan a trip
    result = await planner.plan_trip(
        query="Plan a 5-day trip to Tokyo in March for 2 people",
        budget=5000.0,
        preferences={
            "cabin_class": "economy",
            "hotel_rating": 4,
            "activities": ["museums", "restaurants"]
        }
    )

    # Access results
    print(result["itinerary"])
    print(f"\nFlights found: {len(result['flight_options'])}")
    print(f"Hotels found: {len(result['hotel_options'])}")
    print(f"Total cost: ${result['total_cost']}")

    # Flight options
    for flight in result["flight_options"]:
        print(f"- {flight['airline']}: ${flight['price']}")

# Run
asyncio.run(main())
```

---

## üìä LangSmith Monitoring

### Setup

1. **Get API key:**
   - Visit https://smith.langchain.com/
   - Sign up/login
   - Go to Settings ‚Üí API Keys
   - Create new key

2. **Configure .env:**
   ```bash
   LANGCHAIN_TRACING_V2=true
   LANGCHAIN_API_KEY=ls__your_key_here
   LANGCHAIN_PROJECT=travel-planner-v2
   ```

3. **Verify monitoring:**
   ```python
   from src_v2.monitoring import is_monitoring_enabled

   print(is_monitoring_enabled())  # Should print True
   ```

### View Traces

1. Start your application (API or Streamlit)
2. Make some requests
3. Go to https://smith.langchain.com/
4. Select your project: `travel-planner-v2`
5. View traces in real-time!

**What you'll see:**
- ‚úÖ Intent classification step
- ‚úÖ Parallel search executions
- ‚úÖ Itinerary generation
- ‚úÖ Token usage per step
- ‚úÖ Latency breakdown
- ‚úÖ Error tracking

---

## üéØ Context Preservation in Chat

The Streamlit chat interface maintains context across messages:

**How it works:**

1. **First message:**
   ```
   You: I want to fly from Istanbul to Paris
   ```
   - System extracts: origin=Istanbul, destination=Paris
   - Stores in session context

2. **Follow-up messages use context:**
   ```
   You: Show me hotels
   ```
   - System knows destination=Paris from previous message
   - Searches hotels in Paris automatically

3. **Context updates:**
   ```
   You: Actually, make it Barcelona instead
   ```
   - System updates: destination=Barcelona
   - All future queries use Barcelona

4. **Context persists until cleared:**
   - Click "Clear Context" to reset
   - Click "New Conversation" to start fresh

**Context includes:**
- üìç Origin and destination
- üìÖ Travel dates
- üë• Number of passengers
- üí∞ Budget
- ‚öôÔ∏è Preferences

---

## üîß Configuration Options

### LLM Providers

**Anthropic Claude (Recommended):**
```python
planner = TravelPlannerV2(provider="anthropic", model="claude-sonnet-4-5-20250929")
```

**OpenAI GPT:**
```python
planner = TravelPlannerV2(provider="openai", model="gpt-4-turbo-preview")
```

**OpenRouter (Budget-friendly):**
```python
planner = TravelPlannerV2(
    provider="openrouter",
    model="google/gemini-pro-1.5"  # Cheap and good
)
```

### Monitoring Control

**Enable monitoring:**
```python
planner = TravelPlannerV2(enable_monitoring=True)
```

**Disable monitoring:**
```python
planner = TravelPlannerV2(enable_monitoring=False)
```

### Verbose Output

**Enable verbose logging:**
```python
planner = TravelPlannerV2(verbose=True)
```

---

## üê≥ Docker Deployment (Optional)

**Coming soon: Docker Compose setup for production deployment**

---

## üìà Performance Benchmarks

Based on V1 vs V2 comparison:

| Metric | V1 (DeepAgent) | V2 (LangGraph) | Improvement |
|--------|----------------|----------------|-------------|
| Latency | ~20s | ~4s | **5x faster** |
| Cost/Request | $0.126 | $0.021 | **6x cheaper** |
| LLM Calls | 12 | 2 | **6x fewer** |
| Parallelism | ‚ùå Sequential | ‚úÖ Parallel | Native |
| Monitoring | ‚ö†Ô∏è Limited | ‚úÖ Full | LangSmith |

**Cost at scale (10K requests/day):**
- V1: $1,260/day = **$37,800/month**
- V2: $210/day = **$6,300/month**
- **Savings: $31,500/month** üí∞

---

## üß™ Testing

**Run quick test:**

```bash
# Test V2 workflow
python -c "
import asyncio
from src_v2 import plan_trip

async def test():
    result = await plan_trip('Plan a weekend trip to Paris')
    print('‚úÖ Test passed!' if result else '‚ùå Test failed!')

asyncio.run(test())
"
```

**Test API:**
```bash
# Start API
uvicorn api_v2:app --reload &

# Wait for startup
sleep 3

# Test endpoint
curl http://localhost:8000/health

# Stop API
pkill -f "uvicorn api_v2:app"
```

**Test Streamlit:**
```bash
# Run in headless mode (testing)
streamlit run streamlit_chat_v2.py --server.headless true
```

---

## üÜò Troubleshooting

### Issue: "Planner not initialized"

**Solution:**
- Check API keys in `.env`
- Verify at least one LLM provider is configured
- Check logs for initialization errors

### Issue: "LangSmith tracing not working"

**Solution:**
```bash
# Verify environment
python -c "
import os
from dotenv import load_dotenv
load_dotenv()
print('LANGCHAIN_TRACING_V2:', os.getenv('LANGCHAIN_TRACING_V2'))
print('LANGCHAIN_API_KEY:', 'SET' if os.getenv('LANGCHAIN_API_KEY') else 'NOT SET')
"
```

### Issue: "Context not preserved in Streamlit"

**Solution:**
- Ensure you're not refreshing the page
- Click "Initialize Planner" after configuration changes
- Check session state in sidebar

### Issue: "FastAPI port already in use"

**Solution:**
```bash
# Kill existing process
lsof -ti:8000 | xargs kill -9

# Or use different port
uvicorn api_v2:app --port 8001
```

---

## üìö Additional Resources

- [V1 vs V2 Comparison](./V1_VS_V2_COMPARISON.md)
- [Detailed Architecture Comparison](./DETAILED_COMPARISON.md)
- [V2 Architecture Guide](./src_v2/README.md)
- [LangSmith Documentation](https://docs.smith.langchain.com/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Streamlit Documentation](https://docs.streamlit.io/)

---

## üéâ Next Steps

1. ‚úÖ **Setup monitoring**: Enable LangSmith for production insights
2. ‚úÖ **Choose deployment**: FastAPI for API, Streamlit for UI, or both
3. ‚úÖ **Test with real data**: Replace mock tools with actual APIs
4. ‚úÖ **Scale**: Add load balancing, caching, rate limiting
5. ‚úÖ **Enhance**: Add NDC integration, ML ranking, personalization

---

**Version:** 2.0.0
**Last Updated:** 2025-11-23
**Status:** ‚úÖ Production Ready
